{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "print(f\"PyTorch has version {torch.__version__} with cuda {torch.version.cuda}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df8d294-64d8-438f-a606-804dfc0ae710",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install torch geometric\n",
    "!pip install torch-cluster -f https://data.pyg.org/whl/torch-2.6.0+cu124.html\n",
    "!pip install torch-scatter -f https://data.pyg.org/whl/torch-2.6.0+cu124.html\n",
    "!pip install torch-sparse -f https://data.pyg.org/whl/torch-2.6.0+cu124.html\n",
    "!pip install torch-geometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b27d6d1-c06f-4551-a854-3b04ff91a1a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import torch_geometric as pyg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92db96d4-cfb1-4dc8-8095-b35c9761ab84",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InteractionNetwork(pyg.nn.MessagePassing):\n",
    "   def __init__(self, hidden_size, layers=3):\n",
    "       super().__init__()\n",
    "       self.lin_edge = MLP(hidden_size * 3, hidden_size, layers)\n",
    "       self.lin_node = MLP(hidden_size * 2, hidden_size, layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f36024f-4fe4-4e35-968f-e9ea0534d691",
   "metadata": {},
   "outputs": [],
   "source": [
    "def message(self, x_i, x_j, edge_feature):\n",
    "    x = torch.cat((x_i, x_j, edge_feature), dim=-1)\n",
    "    x = self.lin_edge(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d113a8dd-001b-4ea2-832f-08013eec9b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate(self, inputs, index):\n",
    "    out = torch_scatter.scatter(inputs, index, dim=self.node_dim, reduce=\"sum\")\n",
    "    return (inputs, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d54da6d5-66a0-46ff-8726-7a6933125a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(self, x, edge_index, edge_feature):\n",
    "    edge_out, aggr = self.propagate(edge_index, x=(x, x), edge_feature=edge_feature)\n",
    "    node_out = self.lin_node(torch.cat((x, aggr), dim=-1))\n",
    "    edge_out = edge_feature + edge_out\n",
    "    node_out = x + node_out\n",
    "    return node_out, edge_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "766cb974-fdc7-4e8d-bb71-8a279e624f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LearnedSimulator(torch.nn.Module):\n",
    "   \"\"\"Graph Network-based Simulators(GNS)\"\"\"\n",
    "   def __init__(\n",
    "       self,\n",
    "       hidden_size=128,\n",
    "       n_mp_layers=10, # number of GNN layers\n",
    "       node_feature_dim=30,\n",
    "       edge_feature_dim=3,\n",
    "       dim=2, # dimension of the world, typically 2D or 3D\n",
    "   ):\n",
    "       super().__init__()\n",
    "       self.node_in = MLP(node_feature_dim, hidden_size, 3)\n",
    "       self.edge_in = MLP(edge_feature_dim, hidden_size, 3)\n",
    "       self.node_out = MLP(hidden_size, dim, 3)\n",
    "       self.layers = torch.nn.ModuleList([InteractionNetwork(hidden_size, 3) for _ in range(n_mp_layers)])\n",
    "\n",
    "   def forward(self, edge_index, node_feature, edge_feature):\n",
    "       # encoder\n",
    "       node_feature = self.node_in(node_feature)\n",
    "       edge_feature = self.edge_in(edge_feature)\n",
    "       # processor\n",
    "       for layer in self.layers:\n",
    "           node_feature, edge_feature = layer(node_feature, edge_index, edge_feature=edge_feature)\n",
    "       # decoder\n",
    "       out = self.node_out(node_feature)\n",
    "       return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f6e110f-cf40-4358-81c9-ffae4ae15459",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_NAME = \"WaterDropSample\"\n",
    "OUTPUT_DIR = \"./WaterDropSample\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826524b6-a940-4fcb-99b2-c9db99915e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -O WaterDropSample.zip https://github.com/kks32-courses/sciml/raw/main/docs/04-gns/WaterDropSample.zip\n",
    "!unzip WaterDropSample.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cfce3eb-293b-4513-a71f-4f8637f7d987",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import torch_geometric as pyg\n",
    "\n",
    "def generate_noise(position_seq, noise_std):\n",
    "    \"\"\"Generate noise for a trajectory\"\"\"\n",
    "    velocity_seq = position_seq[:, 1:] - position_seq[:, :-1]\n",
    "    time_steps = velocity_seq.size(1)\n",
    "    velocity_noise = torch.randn_like(velocity_seq) * (noise_std / time_steps ** 0.5)\n",
    "    velocity_noise = velocity_noise.cumsum(dim=1)\n",
    "    position_noise = velocity_noise.cumsum(dim=1)\n",
    "    position_noise = torch.cat((torch.zeros_like(position_noise)[:, 0:1], position_noise), dim=1)\n",
    "    return position_noise\n",
    "\n",
    "\n",
    "def preprocess(particle_type, position_seq, target_position, metadata, noise_std):\n",
    "    \"\"\"Preprocess a trajectory and construct the graph\"\"\"\n",
    "    # apply noise to the trajectory\n",
    "    position_noise = generate_noise(position_seq, noise_std)\n",
    "    position_seq = position_seq + position_noise\n",
    "\n",
    "    # calculate the velocities of particles\n",
    "    recent_position = position_seq[:, -1]\n",
    "    velocity_seq = position_seq[:, 1:] - position_seq[:, :-1]\n",
    "\n",
    "    # construct the graph based on the distances between particles\n",
    "    n_particle = recent_position.size(0)\n",
    "    edge_index = pyg.nn.radius_graph(recent_position, metadata[\"default_connectivity_radius\"], loop=True, max_num_neighbors=n_particle)\n",
    "\n",
    "    # node-level features: velocity, distance to the boundary\n",
    "    normal_velocity_seq = (velocity_seq - torch.tensor(metadata[\"vel_mean\"])) / torch.sqrt(torch.tensor(metadata[\"vel_std\"]) ** 2 + noise_std ** 2)\n",
    "    boundary = torch.tensor(metadata[\"bounds\"])\n",
    "    distance_to_lower_boundary = recent_position - boundary[:, 0]\n",
    "    distance_to_upper_boundary = boundary[:, 1] - recent_position\n",
    "    distance_to_boundary = torch.cat((distance_to_lower_boundary, distance_to_upper_boundary), dim=-1)\n",
    "    distance_to_boundary = torch.clip(distance_to_boundary / metadata[\"default_connectivity_radius\"], -1.0, 1.0)\n",
    "\n",
    "    # edge-level features: displacement, distance\n",
    "    dim = recent_position.size(-1)\n",
    "    edge_displacement = (torch.gather(recent_position, dim=0, index=edge_index[0].unsqueeze(-1).expand(-1, dim)) -\n",
    "                   torch.gather(recent_position, dim=0, index=edge_index[1].unsqueeze(-1).expand(-1, dim)))\n",
    "    edge_displacement /= metadata[\"default_connectivity_radius\"]\n",
    "    edge_distance = torch.norm(edge_displacement, dim=-1, keepdim=True)\n",
    "\n",
    "    # ground truth for training\n",
    "    if target_position is not None:\n",
    "        last_velocity = velocity_seq[:, -1]\n",
    "        next_velocity = target_position + position_noise[:, -1] - recent_position\n",
    "        acceleration = next_velocity - last_velocity\n",
    "        acceleration = (acceleration - torch.tensor(metadata[\"acc_mean\"])) / torch.sqrt(torch.tensor(metadata[\"acc_std\"]) ** 2 + noise_std ** 2)\n",
    "    else:\n",
    "        acceleration = None\n",
    "\n",
    "    # return the graph with features\n",
    "    graph = pyg.data.Data(\n",
    "        x=particle_type,\n",
    "        edge_index=edge_index,\n",
    "        edge_attr=torch.cat((edge_displacement, edge_distance), dim=-1),\n",
    "        y=acceleration,\n",
    "        pos=torch.cat((velocity_seq.reshape(velocity_seq.size(0), -1), distance_to_boundary), dim=-1)\n",
    "    )\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c518dcde-19f1-4843-8eb4-50189be4b481",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OneStepDataset(pyg.data.Dataset):\n",
    "    def __init__(self, data_path, split, window_length=7, noise_std=0.0, return_pos=False):\n",
    "        super().__init__()\n",
    "\n",
    "        # load dataset from the disk\n",
    "        with open(os.path.join(data_path, \"metadata.json\")) as f:\n",
    "            self.metadata = json.load(f)\n",
    "        with open(os.path.join(data_path, f\"{split}_offset.json\")) as f:\n",
    "            self.offset = json.load(f)\n",
    "        self.offset = {int(k): v for k, v in self.offset.items()}\n",
    "        self.window_length = window_length\n",
    "        self.noise_std = noise_std\n",
    "        self.return_pos = return_pos\n",
    "\n",
    "        self.particle_type = np.memmap(os.path.join(data_path, f\"{split}_particle_type.dat\"), dtype=np.int64, mode=\"r\")\n",
    "        self.position = np.memmap(os.path.join(data_path, f\"{split}_position.dat\"), dtype=np.float32, mode=\"r\")\n",
    "\n",
    "        for traj in self.offset.values():\n",
    "            self.dim = traj[\"position\"][\"shape\"][2]\n",
    "            break\n",
    "\n",
    "        # cut particle trajectories according to time slices\n",
    "        self.windows = []\n",
    "        for traj in self.offset.values():\n",
    "            size = traj[\"position\"][\"shape\"][1]\n",
    "            length = traj[\"position\"][\"shape\"][0] - window_length + 1\n",
    "            for i in range(length):\n",
    "                desc = {\n",
    "                    \"size\": size,\n",
    "                    \"type\": traj[\"particle_type\"][\"offset\"],\n",
    "                    \"pos\": traj[\"position\"][\"offset\"] + i * size * self.dim,\n",
    "                }\n",
    "                self.windows.append(desc)\n",
    "\n",
    "    def len(self):\n",
    "        return len(self.windows)\n",
    "\n",
    "    def get(self, idx):\n",
    "        # load corresponding data for this time slice\n",
    "        window = self.windows[idx]\n",
    "        size = window[\"size\"]\n",
    "        particle_type = self.particle_type[window[\"type\"]: window[\"type\"] + size].copy()\n",
    "        particle_type = torch.from_numpy(particle_type)\n",
    "        position_seq = self.position[window[\"pos\"]: window[\"pos\"] + self.window_length * size * self.dim].copy()\n",
    "        position_seq.resize(self.window_length, size, self.dim)\n",
    "        position_seq = position_seq.transpose(1, 0, 2)\n",
    "        target_position = position_seq[:, -1]\n",
    "        position_seq = position_seq[:, :-1]\n",
    "        target_position = torch.from_numpy(target_position)\n",
    "        position_seq = torch.from_numpy(position_seq)\n",
    "\n",
    "        # construct the graph\n",
    "        with torch.no_grad():\n",
    "            graph = preprocess(particle_type, position_seq, target_position, self.metadata, self.noise_std)\n",
    "        if self.return_pos:\n",
    "          return graph, position_seq[:, -1]\n",
    "        return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af544aa-39ae-4f31-b75f-d4d1ce1b2004",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RolloutDataset(pyg.data.Dataset):\n",
    "    def __init__(self, data_path, split, window_length=7):\n",
    "        super().__init__()\n",
    "\n",
    "        # load data from the disk\n",
    "        with open(os.path.join(data_path, \"metadata.json\")) as f:\n",
    "            self.metadata = json.load(f)\n",
    "        with open(os.path.join(data_path, f\"{split}_offset.json\")) as f:\n",
    "            self.offset = json.load(f)\n",
    "        self.offset = {int(k): v for k, v in self.offset.items()}\n",
    "        self.window_length = window_length\n",
    "\n",
    "        self.particle_type = np.memmap(os.path.join(data_path, f\"{split}_particle_type.dat\"), dtype=np.int64, mode=\"r\")\n",
    "        self.position = np.memmap(os.path.join(data_path, f\"{split}_position.dat\"), dtype=np.float32, mode=\"r\")\n",
    "\n",
    "        for traj in self.offset.values():\n",
    "            self.dim = traj[\"position\"][\"shape\"][2]\n",
    "            break\n",
    "\n",
    "    def len(self):\n",
    "        return len(self.offset)\n",
    "\n",
    "    def get(self, idx):\n",
    "        traj = self.offset[idx]\n",
    "        size = traj[\"position\"][\"shape\"][1]\n",
    "        time_step = traj[\"position\"][\"shape\"][0]\n",
    "        particle_type = self.particle_type[traj[\"particle_type\"][\"offset\"]: traj[\"particle_type\"][\"offset\"] + size].copy()\n",
    "        particle_type = torch.from_numpy(particle_type)\n",
    "        position = self.position[traj[\"position\"][\"offset\"]: traj[\"position\"][\"offset\"] + time_step * size * self.dim].copy()\n",
    "        position.resize(traj[\"position\"][\"shape\"])\n",
    "        position = torch.from_numpy(position)\n",
    "        data = {\"particle_type\": particle_type, \"position\": position}\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da1ae492-51a6-4e55-8b08-6e8cea72d8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "\n",
    "dataset_sample = OneStepDataset(OUTPUT_DIR, \"valid\", return_pos=True)\n",
    "graph, position = dataset_sample[0]\n",
    "\n",
    "print(f\"The first item in the valid set is a graph: {graph}\")\n",
    "print(f\"This graph has {graph.num_nodes} nodes and {graph.num_edges} edges.\")\n",
    "print(f\"Each node is a particle and each edge is the interaction between two particles.\")\n",
    "print(f\"Each node has {graph.num_node_features} categorial feature (Data.x), which represents the type of the node.\")\n",
    "print(f\"Each node has a {graph.pos.size(1)}-dim feature vector (Data.pos), which represents the positions and velocities of the particle (node) in several frames.\")\n",
    "print(f\"Each edge has a {graph.num_edge_features}-dim feature vector (Data.edge_attr), which represents the relative distance and displacement between particles.\")\n",
    "print(f\"The model is expected to predict a {graph.y.size(1)}-dim vector for each node (Data.y), which represents the acceleration of the particle.\")\n",
    "\n",
    "# remove directions of edges, because it is a symmetric directed graph.\n",
    "nx_graph = pyg.utils.to_networkx(graph).to_undirected()\n",
    "# remove self loops, because every node has a self loop.\n",
    "nx_graph.remove_edges_from(nx.selfloop_edges(nx_graph))\n",
    "plt.figure(figsize=(7, 7))\n",
    "nx.draw(nx_graph, pos={i: tuple(v) for i, v in enumerate(position)}, node_size=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce87095-2de8-448d-83f5-aa2bbdb5fd88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch_scatter\n",
    "\n",
    "class MLP(torch.nn.Module):\n",
    "    \"\"\"Multi-Layer perceptron\"\"\"\n",
    "    def __init__(self, input_size, hidden_size, output_size, layers, layernorm=True):\n",
    "        super().__init__()\n",
    "        self.layers = torch.nn.ModuleList()\n",
    "        for i in range(layers):\n",
    "            self.layers.append(torch.nn.Linear(\n",
    "                input_size if i == 0 else hidden_size,\n",
    "                output_size if i == layers - 1 else hidden_size,\n",
    "            ))\n",
    "            if i != layers - 1:\n",
    "                self.layers.append(torch.nn.ReLU())\n",
    "        if layernorm:\n",
    "            self.layers.append(torch.nn.LayerNorm(output_size))\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        for layer in self.layers:\n",
    "            if isinstance(layer, torch.nn.Linear):\n",
    "                layer.weight.data.normal_(0, 1 / math.sqrt(layer.in_features))\n",
    "                layer.bias.data.fill_(0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "559b3cfa-04d4-485b-8992-b4c687d45b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InteractionNetwork(pyg.nn.MessagePassing):\n",
    "    \"\"\"Interaction Network as proposed in this paper:\n",
    "    https://proceedings.neurips.cc/paper/2016/hash/3147da8ab4a0437c15ef51a5cc7f2dc4-Abstract.html\"\"\"\n",
    "    def __init__(self, hidden_size, layers):\n",
    "        super().__init__()\n",
    "        self.lin_edge = MLP(hidden_size * 3, hidden_size, hidden_size, layers)\n",
    "        self.lin_node = MLP(hidden_size * 2, hidden_size, hidden_size, layers)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_feature):\n",
    "        edge_out, aggr = self.propagate(edge_index, x=(x, x), edge_feature=edge_feature)\n",
    "        node_out = self.lin_node(torch.cat((x, aggr), dim=-1))\n",
    "        edge_out = edge_feature + edge_out\n",
    "        node_out = x + node_out\n",
    "        return node_out, edge_out\n",
    "\n",
    "    def message(self, x_i, x_j, edge_feature):\n",
    "        x = torch.cat((x_i, x_j, edge_feature), dim=-1)\n",
    "        x = self.lin_edge(x)\n",
    "        return x\n",
    "\n",
    "    def aggregate(self, inputs, index, dim_size=None):\n",
    "        out = torch_scatter.scatter(inputs, index, dim=self.node_dim, dim_size=dim_size, reduce=\"sum\")\n",
    "        return (inputs, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac23a79-0118-4d44-a48d-e80c5d831e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LearnedSimulator(torch.nn.Module):\n",
    "    \"\"\"Graph Network-based Simulators(GNS)\"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        hidden_size=128,\n",
    "        n_mp_layers=10, # number of GNN layers\n",
    "        num_particle_types=9,\n",
    "        particle_type_dim=16, # embedding dimension of particle types\n",
    "        dim=2, # dimension of the world, typical 2D or 3D\n",
    "        window_size=5, # the model looks into W frames before the frame to be predicted\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.window_size = window_size\n",
    "        self.embed_type = torch.nn.Embedding(num_particle_types, particle_type_dim)\n",
    "        self.node_in = MLP(particle_type_dim + dim * (window_size + 2), hidden_size, hidden_size, 3)\n",
    "        self.edge_in = MLP(dim + 1, hidden_size, hidden_size, 3)\n",
    "        self.node_out = MLP(hidden_size, hidden_size, dim, 3, layernorm=False)\n",
    "        self.n_mp_layers = n_mp_layers\n",
    "        self.layers = torch.nn.ModuleList([InteractionNetwork(\n",
    "            hidden_size, 3\n",
    "        ) for _ in range(n_mp_layers)])\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        torch.nn.init.xavier_uniform_(self.embed_type.weight)\n",
    "\n",
    "    def forward(self, data):\n",
    "        # pre-processing\n",
    "        # node feature: combine categorial feature data.x and contiguous feature data.pos.\n",
    "        node_feature = torch.cat((self.embed_type(data.x), data.pos), dim=-1)\n",
    "        node_feature = self.node_in(node_feature)\n",
    "        edge_feature = self.edge_in(data.edge_attr)\n",
    "        # stack of GNN layers\n",
    "        for i in range(self.n_mp_layers):\n",
    "            node_feature, edge_feature = self.layers[i](node_feature, data.edge_index, edge_feature=edge_feature)\n",
    "        # post-processing\n",
    "        out = self.node_out(node_feature)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba0fa2b-c1ff-4b23-b4d5-7d6592cf2f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = OUTPUT_DIR\n",
    "model_path = os.path.join(\"temp\", \"models\", DATASET_NAME)\n",
    "rollout_path = os.path.join(\"temp\", \"rollouts\", DATASET_NAME)\n",
    "\n",
    "!mkdir -p \"$model_path\"\n",
    "!mkdir -p \"$rollout_path\"\n",
    "\n",
    "params = {\n",
    "    \"epoch\": 1,\n",
    "    \"batch_size\": 4,\n",
    "    \"lr\": 1e-4,\n",
    "    \"noise\": 3e-4,\n",
    "    \"save_interval\": 1000,\n",
    "    \"eval_interval\": 1000,\n",
    "    \"rollout_interval\": 200000,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fdc3445-d498-49d9-9f52-f04cb7f91a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rollout(model, data, metadata, noise_std):\n",
    "    device = next(model.parameters()).device\n",
    "    model.eval()\n",
    "    window_size = model.window_size + 1\n",
    "    total_time = data[\"position\"].size(0)\n",
    "    traj = data[\"position\"][:window_size]\n",
    "    traj = traj.permute(1, 0, 2)\n",
    "    particle_type = data[\"particle_type\"]\n",
    "\n",
    "    for time in range(total_time - window_size):\n",
    "        with torch.no_grad():\n",
    "            graph = preprocess(particle_type, traj[:, -window_size:], None, metadata, 0.0)\n",
    "            graph = graph.to(device)\n",
    "            acceleration = model(graph).cpu()\n",
    "            acceleration = acceleration * torch.sqrt(torch.tensor(metadata[\"acc_std\"]) ** 2 + noise_std ** 2) + torch.tensor(metadata[\"acc_mean\"])\n",
    "\n",
    "            recent_position = traj[:, -1]\n",
    "            recent_velocity = recent_position - traj[:, -2]\n",
    "            new_velocity = recent_velocity + acceleration\n",
    "            new_position = recent_position + new_velocity\n",
    "            traj = torch.cat((traj, new_position.unsqueeze(1)), dim=1)\n",
    "\n",
    "    return traj\n",
    "\n",
    "\n",
    "def oneStepMSE(simulator, dataloader, metadata, noise):\n",
    "    \"\"\"Returns two values, loss and MSE\"\"\"\n",
    "    total_loss = 0.0\n",
    "    total_mse = 0.0\n",
    "    batch_count = 0\n",
    "    simulator.eval()\n",
    "    with torch.no_grad():\n",
    "        scale = torch.sqrt(torch.tensor(metadata[\"acc_std\"]) ** 2 + noise ** 2).cuda()\n",
    "        for data in valid_loader:\n",
    "            data = data.cuda()\n",
    "            pred = simulator(data)\n",
    "            mse = ((pred - data.y) * scale) ** 2\n",
    "            mse = mse.sum(dim=-1).mean()\n",
    "            loss = ((pred - data.y) ** 2).mean()\n",
    "            total_mse += mse.item()\n",
    "            total_loss += loss.item()\n",
    "            batch_count += 1\n",
    "    return total_loss / batch_count, total_mse / batch_count\n",
    "\n",
    "\n",
    "def rolloutMSE(simulator, dataset, noise):\n",
    "    total_loss = 0.0\n",
    "    batch_count = 0\n",
    "    simulator.eval()\n",
    "    with torch.no_grad():\n",
    "        for rollout_data in dataset:\n",
    "            rollout_out = rollout(simulator, rollout_data, dataset.metadata, noise)\n",
    "            rollout_out = rollout_out.permute(1, 0, 2)\n",
    "            loss = (rollout_out - rollout_data[\"position\"]) ** 2\n",
    "            loss = loss.sum(dim=-1).mean()\n",
    "            total_loss += loss.item()\n",
    "            batch_count += 1\n",
    "    return total_loss / batch_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2774d033-d8bb-4d91-bb6c-94f352e47757",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def train(params, simulator, train_loader, valid_loader, valid_rollout_dataset):\n",
    "    loss_fn = torch.nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(simulator.parameters(), lr=params[\"lr\"])\n",
    "    scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.1 ** (1 / 5e6))\n",
    "\n",
    "    # recording loss curve\n",
    "    train_loss_list = []\n",
    "    eval_loss_list = []\n",
    "    onestep_mse_list = []\n",
    "    rollout_mse_list = []\n",
    "    total_step = 0\n",
    "\n",
    "    for i in range(params[\"epoch\"]):\n",
    "        simulator.train()\n",
    "        progress_bar = tqdm(train_loader, desc=f\"Epoch {i}\")\n",
    "        total_loss = 0\n",
    "        batch_count = 0\n",
    "        for data in progress_bar:\n",
    "            optimizer.zero_grad()\n",
    "            data = data.cuda()\n",
    "            pred = simulator(data)\n",
    "            loss = loss_fn(pred, data.y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            total_loss += loss.item()\n",
    "            batch_count += 1\n",
    "            progress_bar.set_postfix({\"loss\": loss.item(), \"avg_loss\": total_loss / batch_count, \"lr\": optimizer.param_groups[0][\"lr\"]})\n",
    "            total_step += 1\n",
    "            train_loss_list.append((total_step, loss.item()))\n",
    "\n",
    "            # evaluation\n",
    "            if total_step % params[\"eval_interval\"] == 0:\n",
    "                simulator.eval()\n",
    "                eval_loss, onestep_mse = oneStepMSE(simulator, valid_loader, valid_dataset.metadata, params[\"noise\"])\n",
    "                eval_loss_list.append((total_step, eval_loss))\n",
    "                onestep_mse_list.append((total_step, onestep_mse))\n",
    "                tqdm.write(f\"\\nEval: Loss: {eval_loss}, One Step MSE: {onestep_mse}\")\n",
    "                simulator.train()\n",
    "\n",
    "            # do rollout on valid set\n",
    "            if total_step % params[\"rollout_interval\"] == 0:\n",
    "                simulator.eval()\n",
    "                rollout_mse = rolloutMSE(simulator, valid_rollout_dataset, params[\"noise\"])\n",
    "                rollout_mse_list.append((total_step, rollout_mse))\n",
    "                tqdm.write(f\"\\nEval: Rollout MSE: {rollout_mse}\")\n",
    "                simulator.train()\n",
    "\n",
    "            # save model\n",
    "            if total_step % params[\"save_interval\"] == 0:\n",
    "                torch.save(\n",
    "                    {\n",
    "                        \"model\": simulator.state_dict(),\n",
    "                        \"optimizer\": optimizer.state_dict(),\n",
    "                        \"scheduler\": scheduler.state_dict(),\n",
    "                    },\n",
    "                    os.path.join(model_path, f\"checkpoint_{total_step}.pt\")\n",
    "                )\n",
    "    return train_loss_list, eval_loss_list, onestep_mse_list, rollout_mse_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d98bef-4bc2-4e0a-80cd-67c1e8776190",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the model is time-consuming. We highly recommend you to skip this block and load the checkpoint in the next block.\n",
    "\n",
    "# load dataset\n",
    "train_dataset = OneStepDataset(data_path, \"train\", noise_std=params[\"noise\"])\n",
    "valid_dataset = OneStepDataset(data_path, \"valid\", noise_std=params[\"noise\"])\n",
    "train_loader = pyg.loader.DataLoader(train_dataset, batch_size=params[\"batch_size\"], shuffle=True, pin_memory=True, num_workers=2)\n",
    "valid_loader = pyg.loader.DataLoader(valid_dataset, batch_size=params[\"batch_size\"], shuffle=False, pin_memory=True, num_workers=2)\n",
    "valid_rollout_dataset = RolloutDataset(data_path, \"valid\")\n",
    "\n",
    "# build model\n",
    "simulator = LearnedSimulator()\n",
    "simulator = simulator.cuda()\n",
    "\n",
    "# train the model\n",
    "train_loss_list, eval_loss_list, onestep_mse_list, rollout_mse_list = train(params, simulator, train_loader, valid_loader, valid_rollout_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73eed1b9-beaf-43d0-aab1-fa116b96cc5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# visualize the loss curve\n",
    "plt.figure()\n",
    "plt.plot(*zip(*train_loss_list), label=\"train\")\n",
    "plt.plot(*zip(*eval_loss_list), label=\"valid\")\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
